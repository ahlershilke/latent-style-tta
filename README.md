# Test-Time Data Augmentation using Latent Style Statistics for Enhanced Domain Generalization

This is the repository for my master thesis project, conducted under the tutelage of the chair for Explainable Artificial Intelligence (xAI), University of Bamberg.
The objective of this work was to develop a method for addressing the domain generalization problem under domain shift conditions by explicitly encoding domain-specific style information during training, thereby enabling latent space augmentation at inference time.
This thesis introduces a new method to improve the robustness of deep neural networks when faced with shifts in data distribution by applying data augmentation at test time using latent style statistics. The approach extracts style-related feature statistics from intermediate layers of a pre-trained model and uses these statistics to generate style-transformed variants of each test input. The augmented inputs are then processed by the model and their predictions are aggregated, reducing sensitivity to domain-specific variations. Experiments on standard domain generalization benchmarks demonstrate that this test-time augmentation can improve accuracy on unseen target domains compared to models without augmentation. 
